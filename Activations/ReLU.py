import numpy as np
from activation import Activation

class ReLu():
    def __init__(self) -> None:
        def relu(x):
            #relu calculation
            return 
        
        def relu_derivative(x):
            return 
        
        super.__init__(relu,relu_derivative)
        